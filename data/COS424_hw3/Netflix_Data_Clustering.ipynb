{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Netflix Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework assignment, you will analyze the netflix prize data. The data consist of 100,480,50 movie ratings on a scale from 0 to 5 stars. The reveiws are distributed across 17,770 movies and 480,189. We have provided the training data as a sparse matrix where the row corresponds to the movie ID and the column corresponds to the user ID. A seperate file contains the title and year of release for each movie. The original, raw data consists of multiple lists of tuples; each list is a seperate movie and each tuple is User ID, Rating, and Rating Year. \n",
    "The original data can be downloaded here: https://archive.org/download/nf_prize_dataset.tar\n",
    "Further information about the netflix prize is available online: \n",
    "https://en.wikipedia.org/wiki/Netflix_Prize\n",
    "https://www.netflixprize.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID    Year                          Name\n",
      "0   1  2003.0               Dinosaur Planet\n",
      "1   2  2004.0    Isle of Man TT 2004 Review\n",
      "2   3  1997.0                     Character\n",
      "3   4  1994.0  Paula Abdul's Get Up & Dance\n",
      "4   5  2004.0      The Rise and Fall of ECW\n",
      "(17770, 3)\n"
     ]
    }
   ],
   "source": [
    "# This file consists of titles and release years associated with each ID\n",
    "movie_titles = pd.read_csv('movie_titles.txt', header = None, names = ['ID','Year','Name'], encoding='latin-1')\n",
    "print(movie_titles.head())\n",
    "print(movie_titles.shape)\n",
    "\n",
    "movie_by_id = {}\n",
    "for id, name, year in zip(movie_titles['ID'], movie_titles['Name'], movie_titles['Year']):\n",
    "    if not (np.isnan(year)):\n",
    "        year = str(int(year))\n",
    "    else:\n",
    "        year = 'NaN'\n",
    "    movie_by_id[id] = name + ' ' + '(' + year + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17771, 2649430)\n"
     ]
    }
   ],
   "source": [
    "# This file is a sparse matrix of movies by user, with each element a rating (1-5) or nonresponse (0)\n",
    "ratings_csr = scipy.sparse.load_npz('netflix_full_csr.npz')\n",
    "print(ratings_csr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid memory overflow errors we have randomly subsampled the data. Some computers can handle the full dataset (e.g. 2017 Macbook Pro can perform SVD on the full dataset). Older computers likely need to subsample the data. You can consider using Princeton computing resources and clusters to perform more computationally expensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n_samples = 5000\n",
    "n_viewers = 500000\n",
    "#random_sample_movies = np.random.choice(17771, size = n_samples)\n",
    "random_sample_viewers = np.random.choice(2649430, size = n_viewers)\n",
    "ratings_small = ratings_csr[:,random_sample_viewers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removing users with no reviews:  (2649430, 17771)\n",
      "(480189, 17771)\n",
      "finished in 24.99 seconds\n"
     ]
    }
   ],
   "source": [
    "# Filter the matrix to remove rows with NO REVIEWS\n",
    "start = time.time()\n",
    "ratings_csc = ratings_csr.T\n",
    "print('before removing users with no reviews: ', ratings_csc.shape)\n",
    "non_zero_users_csc = ratings_csc[(ratings_csc.getnnz(axis=1) != 0)]\n",
    "print(non_zero_users_csc.shape)\n",
    "\n",
    "finish = time.time()\n",
    "print('finished in %.2f seconds' % (finish - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common methods for analyzing large datasets is dimension reduction. Here we perform a truncated SVD suited for sparse datasets and analyze which movies are associated with different latent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = 5000\n",
    "svd = TruncatedSVD(n_components = n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = svd.fit_transform(ratings_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "components = svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22171354  0.0300368   0.02018774  0.01675508  0.01244614]\n"
     ]
    }
   ],
   "source": [
    "print(svd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 0\n",
      "1904    Pirates of the Caribbean: The Curse of the Bla...\n",
      "Name: Name, dtype: object: 618.684\n",
      "11282    Forrest Gump\n",
      "Name: Name, dtype: object: 613.529\n",
      "2451    Lord of the Rings: The Fellowship of the Ring\n",
      "Name: Name, dtype: object: 571.28\n",
      "4305    The Sixth Sense\n",
      "Name: Name, dtype: object: 569.455\n",
      "11520    Lord of the Rings: The Two Towers\n",
      "Name: Name, dtype: object: 568.664\n",
      "14549    The Shawshank Redemption: Special Edition\n",
      "Name: Name, dtype: object: 556.065\n",
      "16376    The Green Mile\n",
      "Name: Name, dtype: object: 555.738\n",
      "15123    Independence Day\n",
      "Name: Name, dtype: object: 542.54\n",
      "13727    Gladiator\n",
      "Name: Name, dtype: object: 538.47\n",
      " \n",
      "Component 1\n",
      "5316    Miss Congeniality\n",
      "Name: Name, dtype: object: 230.629\n",
      "15204    The Day After Tomorrow\n",
      "Name: Name, dtype: object: 225.835\n",
      "2121    Being John Malkovich\n",
      "Name: Name, dtype: object: -218.055\n",
      "9339    Pearl Harbor\n",
      "Name: Name, dtype: object: 217.384\n",
      "4995    Gone in 60 Seconds\n",
      "Name: Name, dtype: object: 210.44\n",
      "6971    Armageddon\n",
      "Name: Name, dtype: object: 209.415\n",
      "6028    Amelie\n",
      "Name: Name, dtype: object: -205.749\n",
      "15581    Sweet Home Alabama\n",
      "Name: Name, dtype: object: 204.742\n",
      "14537    How to Lose a Guy in 10 Days\n",
      "Name: Name, dtype: object: 200.944\n",
      " \n",
      "Component 2\n",
      "12231    Lost in Translation\n",
      "Name: Name, dtype: object: 210.651\n",
      "12581    Mystic River\n",
      "Name: Name, dtype: object: 206.631\n",
      "11606    Hotel Rwanda\n",
      "Name: Name, dtype: object: 192.123\n",
      "3281    Sideways\n",
      "Name: Name, dtype: object: 180.871\n",
      "14102    The Notebook\n",
      "Name: Name, dtype: object: 179.139\n",
      "885    Ray\n",
      "Name: Name, dtype: object: 176.014\n",
      "1904    Pirates of the Caribbean: The Curse of the Bla...\n",
      "Name: Name, dtype: object: 175.721\n",
      "1864    Eternal Sunshine of the Spotless Mind\n",
      "Name: Name, dtype: object: 172.693\n",
      "2912    Finding Neverland\n",
      "Name: Name, dtype: object: 171.253\n",
      " \n",
      "Component 3\n",
      "4576    Steel Magnolias\n",
      "Name: Name, dtype: object: 191.556\n",
      "14453    Kill Bill: Vol. 1\n",
      "Name: Name, dtype: object: -179.574\n",
      "456    Kill Bill: Vol. 2\n",
      "Name: Name, dtype: object: -167.745\n",
      "7616    Dirty Dancing\n",
      "Name: Name, dtype: object: 166.511\n",
      "1541    Sleepless in Seattle\n",
      "Name: Name, dtype: object: 164.423\n",
      "1143    Fried Green Tomatoes\n",
      "Name: Name, dtype: object: 160.098\n",
      "5925    Fight Club\n",
      "Name: Name, dtype: object: -157.804\n",
      "11520    Lord of the Rings: The Two Towers\n",
      "Name: Name, dtype: object: -156.836\n",
      "14239    Lord of the Rings: The Return of the King\n",
      "Name: Name, dtype: object: -153.423\n",
      " \n",
      "Component 4\n",
      "14312    The Patriot\n",
      "Name: Name, dtype: object: 239.255\n",
      "12316    The Rock\n",
      "Name: Name, dtype: object: 211.293\n",
      "15123    Independence Day\n",
      "Name: Name, dtype: object: 204.989\n",
      "16383    The Fugitive\n",
      "Name: Name, dtype: object: 199.993\n",
      "14366    Lethal Weapon 4\n",
      "Name: Name, dtype: object: 195.949\n",
      "13650    Air Force One\n",
      "Name: Name, dtype: object: 195.505\n",
      "16376    The Green Mile\n",
      "Name: Name, dtype: object: 188.646\n",
      "16241    Con Air\n",
      "Name: Name, dtype: object: 187.878\n",
      "7233    Men of Honor\n",
      "Name: Name, dtype: object: 185.805\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(0,n_components):\n",
    "    Z_sort = np.argsort(np.abs(Z[:,i]))\n",
    "    print('Component ' + str(i))\n",
    "    for j in range(1,10):\n",
    "        movie_index = Z_sort[-j]\n",
    "        movie_title = movie_titles[movie_titles['ID'] == movie_index]['Name']\n",
    "        movie_weight = Z[movie_index,i]\n",
    "        print(str(movie_title) + ': ' + str(movie_weight))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3216.24267578,   435.7227478 ,   292.8493042 ,   243.0541687 ,\n",
       "         180.5473938 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_small = non_zero_users_csc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering, AgglomerativeClustering\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie #10, 9    Fighter\n",
      "Name: Name, dtype: object, average rating: 3.18 in 249 reviews\n",
      "X_train : (199, 17770) \t\n",
      "X_test : (50, 17770) \t\n",
      "y_train : (199, 1) \t\n",
      "y_test : (50, 1) \t\n",
      "\n",
      "No Clustering\n",
      "Variance score: 0.16\n",
      "\n",
      "KMeans Clustering\n",
      "Variance score mean: 0.01\n",
      "Variance score mode cluster: -0.01\n",
      "Variance score random cluster: -1.11\n",
      "Variance score regress cluster: 0.19\n",
      "\n",
      "DBSCAN Clustering\n",
      "Variance score mean: -0.01\n",
      "Variance score mode cluster: -0.05\n",
      "Variance score random cluster: -0.87\n",
      "Variance score regress cluster: 0.16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cat/anaconda3/lib/python3.6/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Clustering\n",
      "Variance score mean: -0.24\n",
      "Variance score mode cluster: -0.60\n",
      "Variance score random cluster: -1.18\n",
      "Variance score regress cluster: -0.57\n",
      "\n",
      "Agglomerative Clustering\n",
      "Variance score mean: -0.86\n",
      "Variance score mode cluster: -1.94\n",
      "Variance score random cluster: -1.22\n",
      "Variance score regress cluster: -3.35\n",
      "\n",
      "Movie #11, 10    Full Frame: Documentary Shorts\n",
      "Name: Name, dtype: object, average rating: 3.03 in 198 reviews\n",
      "X_train : (158, 17770) \t\n",
      "X_test : (40, 17770) \t\n",
      "y_train : (158, 1) \t\n",
      "y_test : (40, 1) \t\n",
      "\n",
      "No Clustering\n",
      "Variance score: -0.34\n",
      "\n",
      "KMeans Clustering\n",
      "Variance score mean: -0.23\n",
      "Variance score mode cluster: -0.21\n",
      "Variance score random cluster: -0.73\n",
      "Variance score regress cluster: -0.36\n",
      "\n",
      "DBSCAN Clustering\n",
      "Variance score mean: -0.18\n",
      "Variance score mode cluster: -0.13\n",
      "Variance score random cluster: -0.30\n",
      "Variance score regress cluster: -0.34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cat/anaconda3/lib/python3.6/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Clustering\n",
      "Variance score mean: -0.12\n",
      "Variance score mode cluster: -0.13\n",
      "Variance score random cluster: -1.01\n",
      "Variance score regress cluster: -0.08\n",
      "\n",
      "Agglomerative Clustering\n",
      "Variance score mean: -0.26\n",
      "Variance score mode cluster: -0.21\n",
      "Variance score random cluster: -0.71\n",
      "Variance score regress cluster: -0.15\n",
      "\n",
      "Movie #12, 11    My Favorite Brunette\n",
      "Name: Name, dtype: object, average rating: 3.42 in 546 reviews\n",
      "X_train : (436, 17770) \t\n",
      "X_test : (110, 17770) \t\n",
      "y_train : (436, 1) \t\n",
      "y_test : (110, 1) \t\n",
      "\n",
      "No Clustering\n",
      "Variance score: 0.22\n",
      "\n",
      "KMeans Clustering\n",
      "Variance score mean: -0.05\n",
      "Variance score mode cluster: -0.26\n",
      "Variance score random cluster: -0.84\n",
      "Variance score regress cluster: 0.05\n",
      "\n",
      "DBSCAN Clustering\n",
      "Variance score mean: -0.00\n",
      "Variance score mode cluster: -0.15\n",
      "Variance score random cluster: -0.98\n",
      "Variance score regress cluster: 0.22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cat/anaconda3/lib/python3.6/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Clustering\n",
      "Variance score mean: -0.12\n",
      "Variance score mode cluster: -0.06\n",
      "Variance score random cluster: -0.52\n",
      "Variance score regress cluster: -0.11\n",
      "\n",
      "Agglomerative Clustering\n",
      "Variance score mean: -0.05\n",
      "Variance score mode cluster: -0.09\n",
      "Variance score random cluster: -0.62\n",
      "Variance score regress cluster: 0.03\n",
      "\n",
      "Movie #13, 12    Lord of the Rings: The Return of the King: Ext...\n",
      "Name: Name, dtype: object, average rating: 4.55 in 125 reviews\n",
      "X_train : (100, 17770) \t\n",
      "X_test : (25, 17770) \t\n",
      "y_train : (100, 1) \t\n",
      "y_test : (25, 1) \t\n",
      "\n",
      "No Clustering\n",
      "Variance score: -0.09\n",
      "\n",
      "KMeans Clustering\n",
      "Variance score mean: 0.03\n",
      "Variance score mode cluster: -0.66\n",
      "Variance score random cluster: -1.34\n",
      "Variance score regress cluster: -0.16\n",
      "\n",
      "DBSCAN Clustering\n",
      "Variance score mean: -0.02\n",
      "Variance score mode cluster: -0.66\n",
      "Variance score random cluster: -2.03\n",
      "Variance score regress cluster: -0.09\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cat/anaconda3/lib/python3.6/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Clustering\n",
      "Variance score mean: -0.03\n",
      "Variance score mode cluster: -0.66\n",
      "Variance score random cluster: -1.34\n",
      "Variance score regress cluster: -0.13\n",
      "\n",
      "Agglomerative Clustering\n",
      "Variance score mean: 0.06\n",
      "Variance score mode cluster: -0.66\n",
      "Variance score random cluster: -0.56\n",
      "Variance score regress cluster: -0.06\n",
      "\n",
      "Movie #14, 13    Nature: Antarctica\n",
      "Name: Name, dtype: object, average rating: 3.03 in 118 reviews\n",
      "X_train : (94, 17770) \t\n",
      "X_test : (24, 17770) \t\n",
      "y_train : (94, 1) \t\n",
      "y_test : (24, 1) \t\n",
      "\n",
      "No Clustering\n",
      "Variance score: 0.06\n",
      "\n",
      "KMeans Clustering\n",
      "Variance score mean: -0.01\n",
      "Variance score mode cluster: -0.21\n",
      "Variance score random cluster: -0.21\n",
      "Variance score regress cluster: 0.02\n",
      "\n",
      "DBSCAN Clustering\n",
      "Variance score mean: -0.00\n",
      "Variance score mode cluster: -0.00\n",
      "Variance score random cluster: -0.57\n",
      "Variance score regress cluster: 0.06\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cat/anaconda3/lib/python3.6/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Clustering\n",
      "Variance score mean: -0.03\n",
      "Variance score mode cluster: -0.00\n",
      "Variance score random cluster: -1.21\n",
      "Variance score regress cluster: 0.06\n",
      "\n",
      "Agglomerative Clustering\n",
      "Variance score mean: -0.84\n",
      "Variance score mode cluster: -2.16\n",
      "Variance score random cluster: -1.49\n",
      "Variance score regress cluster: -1.82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_results_dict = {}\n",
    "for id in range(10, 15):\n",
    "    movie_id = id\n",
    "    num_reviews = ratings_small[:,movie_id].count_nonzero()\n",
    "    movie_name = movie_titles[movie_titles['ID'] == movie_id]['Name']\n",
    "    print ('Movie #%s, %s, average rating: %.2f in %i reviews' % (\n",
    "        movie_id,\n",
    "        movie_name,\n",
    "        np.sum(ratings_small[:,movie_id]) / num_reviews,\n",
    "        int(num_reviews)\n",
    "    ))\n",
    "\n",
    "    start = time.time()\n",
    "    filter_by = np.ravel((ratings_small[:,movie_id] != 0.0).toarray())\n",
    "    filtered_ratings = ratings_small[filter_by,:]\n",
    "\n",
    "    movie_mask = np.ravel(np.full((filtered_ratings.shape[1], 1), True))\n",
    "    movie_mask[movie_id] = False\n",
    "    X = filtered_ratings[:,movie_mask]\n",
    "    y = filtered_ratings[:,movie_id]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y.toarray(), test_size=0.2, random_state=0)\n",
    "    finish = time.time()\n",
    "    data_time = (finish - start)\n",
    "    #print 'finished choosing data in %.2f seconds' % data\n",
    "    for i, name in zip([X_train, X_test, y_train, y_test], ['X_train', 'X_test', 'y_train', 'y_test']):\n",
    "        print (name, ':', i.shape, '\\t',)\n",
    "    print()\n",
    "    \n",
    "    # Run the regression on the film\n",
    "    start = time.time()\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_reg = regr.predict(X_test)\n",
    "\n",
    "    #print 'Coefficients: \\n', regr.coef_\n",
    "    #print \"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred)\n",
    "    print('No Clustering')\n",
    "    print('Variance score: %.2f' % r2_score(y_test, y_pred_reg))\n",
    "    print()\n",
    "    finish = time.time()\n",
    "    regr_time = finish - start\n",
    "   # print ('finished regression in %.2f seconds' % regr_time)\n",
    "   # print()\n",
    "    movie_results_dict[id] = {\n",
    "        'name': str(movie_titles[movie_titles['ID'] == movie_id]['Name']),\n",
    "        'regr_time': regr_time,\n",
    "        'data_time': data_time,\n",
    "        'regr': regr,\n",
    "        'mse': mean_squared_error(y_test, y_pred_reg),\n",
    "        'r2': r2_score(y_test, y_pred_reg)\n",
    "    }\n",
    "    \n",
    "    kmeans = KMeans(n_clusters = np.max([int(X_train.shape[0]/50)+1, 3]) , random_state=0, algorithm=\"full\")\n",
    "    kmeans.fit(X_train)\n",
    "    cluster_members = kmeans.labels_\n",
    "    pred_clusters = kmeans.predict(X_test)\n",
    "    \n",
    "    y_pred_avg_km = []\n",
    "    y_pred_rand_km = []\n",
    "    y_pred_clus_km = []\n",
    "    y_pred_mode_km = []\n",
    "    for k in range(len(pred_clusters)):\n",
    "        person = pred_clusters[k]\n",
    "        lookalike_y = y_train[np.where(cluster_members==person)]\n",
    "        y_pred_avg_km.append([np.mean(lookalike_y)])\n",
    "        y_pred_rand_km.append([np.random.choice(lookalike_y.flatten())])\n",
    "        y_pred_mode_km.append(stats.mode(lookalike_y)[0][0])\n",
    "        \n",
    "        lookalike_x = X_train[np.where(cluster_members==person)]\n",
    "        regr = LinearRegression()\n",
    "        regr.fit(lookalike_x, lookalike_y)\n",
    "        y_pred_clus_km.append(regr.predict(X_test[k].reshape(1, -1))[0])\n",
    "        \n",
    "    \n",
    "    y_pred_avg_km = np.asmatrix(y_pred_avg_km)\n",
    "    y_pred_mode_km = np.asmatrix(y_pred_mode_km)\n",
    "    y_pred_rand_km = np.asmatrix(y_pred_rand_km)\n",
    "    y_pred_clus_km = np.asmatrix(y_pred_clus_km)\n",
    "    \n",
    "    print('KMeans Clustering')\n",
    "    print('Variance score mean: %.2f' % r2_score(y_test, y_pred_avg_km))\n",
    "    print('Variance score mode: %.2f' % r2_score(y_test, y_pred_mode_km))\n",
    "    print('Variance score random: %.2f' % r2_score(y_test, y_pred_rand_km))\n",
    "    print('Variance score regress: %.2f' % r2_score(y_test, y_pred_clus_km))\n",
    "    print()\n",
    "    \n",
    "    dbscan = DBSCAN()\n",
    "    dbscan.fit(X_train)\n",
    "    cluster_members = dbscan.labels_\n",
    "    pred_clusters = dbscan.fit_predict(X_test)\n",
    "    \n",
    "    y_pred_avg_db = []\n",
    "    y_pred_mode_db = []\n",
    "    y_pred_rand_db = []\n",
    "    y_pred_clus_db = []\n",
    "    \n",
    "    for k in range(len(pred_clusters)):\n",
    "        person = pred_clusters[k]\n",
    "        lookalike_y = y_train[np.where(cluster_members==person)]\n",
    "        y_pred_avg_db.append([np.mean(lookalike_y)])\n",
    "        y_pred_mode_db.append(stats.mode(lookalike_y)[0][0])\n",
    "        y_pred_rand_db.append([np.random.choice(lookalike_y.flatten())])\n",
    "        \n",
    "        lookalike_x = X_train[np.where(cluster_members==person)]\n",
    "        regr = LinearRegression()\n",
    "        regr.fit(lookalike_x, lookalike_y)\n",
    "        y_pred_clus_db.append(regr.predict(X_test[k].reshape(1, -1))[0])\n",
    "        \n",
    "    \n",
    "    y_pred_avg_db = np.asmatrix(y_pred_avg_db)\n",
    "    y_pred_mode_db = np.asmatrix(y_pred_mode_db)\n",
    "    y_pred_rand_db = np.asmatrix(y_pred_rand_db)\n",
    "    y_pred_clus_db = np.asmatrix(y_pred_clus_db)\n",
    "    \n",
    "    print('DBSCAN Clustering')\n",
    "    print('Variance score mean: %.2f' % r2_score(y_test, y_pred_avg_db))\n",
    "    print('Variance score mode: %.2f' % r2_score(y_test, y_pred_mode_db))\n",
    "    print('Variance score random: %.2f' % r2_score(y_test, y_pred_rand_db))\n",
    "    print('Variance score regress: %.2f' % r2_score(y_test, y_pred_clus_db))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    spect = SpectralClustering(n_clusters = np.max([int(X_train.shape[0]/50)+1, 3]) , random_state=0)\n",
    "    spect.fit(X_train)\n",
    "    cluster_members = spect.labels_\n",
    "    pred_clusters = spect.fit_predict(X_test)\n",
    "    \n",
    "    y_pred_avg_sc = []\n",
    "    y_pred_mode_sc = []\n",
    "    y_pred_rand_sc = []\n",
    "    y_pred_clus_sc = []\n",
    "    \n",
    "    for k in range(len(pred_clusters)):\n",
    "        person = pred_clusters[k]\n",
    "        lookalike_y = y_train[np.where(cluster_members==person)]\n",
    "        y_pred_avg_sc.append([np.mean(lookalike_y)])\n",
    "        y_pred_mode_sc.append(stats.mode(lookalike_y)[0][0])\n",
    "        y_pred_rand_sc.append([np.random.choice(lookalike_y.flatten())])\n",
    "        \n",
    "        lookalike_x = X_train[np.where(cluster_members==person)]\n",
    "        regr = LinearRegression()\n",
    "        regr.fit(lookalike_x, lookalike_y)\n",
    "        y_pred_clus_sc.append(regr.predict(X_test[k].reshape(1, -1))[0])\n",
    "        \n",
    "    \n",
    "    y_pred_avg_sc = np.asmatrix(y_pred_avg_sc)\n",
    "    y_pred_mode_sc = np.asmatrix(y_pred_mode_sc)\n",
    "    y_pred_rand_sc = np.asmatrix(y_pred_rand_sc)\n",
    "    y_pred_clus_sc = np.asmatrix(y_pred_clus_sc)\n",
    "    \n",
    "    print('Spectral Clustering')\n",
    "    print('Variance score mean: %.2f' % r2_score(y_test, y_pred_avg_sc))\n",
    "    print('Variance score mode: %.2f' % r2_score(y_test, y_pred_mode_sc))\n",
    "    print('Variance score random: %.2f' % r2_score(y_test, y_pred_rand_sc))\n",
    "    print('Variance score regress: %.2f' % r2_score(y_test, y_pred_clus_sc))\n",
    "    print()\n",
    "    \n",
    "    agg = AgglomerativeClustering(n_clusters = np.max([int(X_train.shape[0]/50)+1, 3]))\n",
    "    agg.fit(X_train)\n",
    "    cluster_members = agg.labels_\n",
    "    pred_clusters = agg.fit_predict(X_test)\n",
    "    \n",
    "    y_pred_avg_ac = []\n",
    "    y_pred_mode_ac = []\n",
    "    y_pred_rand_ac = []\n",
    "    y_pred_clus_ac = []\n",
    "    \n",
    "    for k in range(len(pred_clusters)):\n",
    "        person = pred_clusters[k]\n",
    "        lookalike_y = y_train[np.where(cluster_members==person)]\n",
    "        y_pred_avg_ac.append([np.mean(lookalike_y)])\n",
    "        y_pred_mode_ac.append(stats.mode(lookalike_y)[0][0])\n",
    "        y_pred_rand_ac.append([np.random.choice(lookalike_y.flatten())])\n",
    "        \n",
    "        lookalike_x = X_train[np.where(cluster_members==person)]\n",
    "        regr = LinearRegression()\n",
    "        regr.fit(lookalike_x, lookalike_y)\n",
    "        y_pred_clus_ac.append(regr.predict(X_test[k].reshape(1, -1))[0])\n",
    "        \n",
    "    \n",
    "    y_pred_avg_ac = np.asmatrix(y_pred_avg_ac)\n",
    "    y_pred_mode_ac = np.asmatrix(y_pred_mode_ac)\n",
    "    y_pred_rand_ac = np.asmatrix(y_pred_rand_ac)\n",
    "    y_pred_clus_ac = np.asmatrix(y_pred_clus_ac)\n",
    "    \n",
    "    print('Agglomerative Clustering')\n",
    "    print('Variance score mean: %.2f' % r2_score(y_test, y_pred_avg_ac))\n",
    "    print('Variance score mode: %.2f' % r2_score(y_test, y_pred_mode_ac))\n",
    "    print('Variance score random: %.2f' % r2_score(y_test, y_pred_rand_ac))\n",
    "    print('Variance score regress: %.2f' % r2_score(y_test, y_pred_clus_ac))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_time': 1.1898272037506104,\n",
       " 'mse': 1.6863325,\n",
       " 'name': '2    Character\\nName: Name, dtype: object',\n",
       " 'r2': -0.74125852269030212,\n",
       " 'regr': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False),\n",
       " 'regr_time': 4.725301027297974}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_results_dict[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cat/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "review_nums = []\n",
    "for i in range(17700):\n",
    "    num_reviews = ratings_small[:,i].count_nonzero()\n",
    "    review_nums.append((i, num_reviews, np.sum(ratings_small[:,i]) / num_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681\t4.5389133627\tFruits Basket (2001)\n",
      "17292\t4.54256303493\tThe Simpsons: Season 5 (1993)\n",
      "92470\t4.54370065967\tStar Wars: Episode V: The Empire Strikes Back (1980)\n",
      "134284\t4.54512078878\tLord of the Rings: The Return of the King (2003)\n",
      "125\t4.552\tLord of the Rings: The Return of the King: Extended Edition: Bonus Material (2003)\n",
      "1883\t4.55443441317\tInu-Yasha (2000)\n",
      "8426\t4.58129598861\tThe Simpsons: Season 6 (1994)\n",
      "6621\t4.58238936717\tArrested Development: Season 2 (2004)\n",
      "220\t4.58636363636\tGhost in the Shell: Stand Alone Complex: 2nd Gig (2005)\n",
      "1238\t4.59208400646\tVeronica Mars: Season 1 (2004)\n",
      "139660\t4.59338393241\tThe Shawshank Redemption: Special Edition (1994)\n",
      "89\t4.59550561798\tTenchi Muyo! Ryo Ohki (1995)\n",
      "25\t4.6\tTrailer Park Boys: Season 4 (2003)\n",
      "75\t4.6\tTrailer Park Boys: Season 3 (2003)\n",
      "1633\t4.60502143295\tFullmetal Alchemist (2004)\n",
      "1747\t4.63880938752\tBattlestar Galactica: Season 1 (2004)\n",
      "7249\t4.67098910195\tLost: Season 1 (2004)\n",
      "74912\t4.70261106365\tLord of the Rings: The Two Towers: Extended Edition (2002)\n",
      "73422\t4.71661082509\tThe Lord of the Rings: The Fellowship of the Ring: Extended Edition (2001)\n",
      "73335\t4.72326992568\tLord of the Rings: The Return of the King: Extended Edition (2003)\n"
     ]
    }
   ],
   "source": [
    "s = sorted(review_nums, key=lambda x: x[2])\n",
    "for movie_id, num, avg_review in s[-20:]:\n",
    "    print ('%s\\t%s\\t%s' % (num, avg_review, movie_by_id[movie_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
