{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Netflix Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework assignment, you will analyze the netflix prize data. The data consist of 100,480,50 movie ratings on a scale from 0 to 5 stars. The reveiws are distributed across 17,770 movies and 480,189. We have provided the training data as a sparse matrix where the row corresponds to the movie ID and the column corresponds to the user ID. A seperate file contains the title and year of release for each movie. The original, raw data consists of multiple lists of tuples; each list is a seperate movie and each tuple is User ID, Rating, and Rating Year. \n",
    "The original data can be downloaded here: https://archive.org/download/nf_prize_dataset.tar\n",
    "Further information about the netflix prize is available online: \n",
    "https://en.wikipedia.org/wiki/Netflix_Prize\n",
    "https://www.netflixprize.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID    Year                          Name\n",
      "0   1  2003.0               Dinosaur Planet\n",
      "1   2  2004.0    Isle of Man TT 2004 Review\n",
      "2   3  1997.0                     Character\n",
      "3   4  1994.0  Paula Abdul's Get Up & Dance\n",
      "4   5  2004.0      The Rise and Fall of ECW\n"
     ]
    }
   ],
   "source": [
    "# This file consists of titles and release years associated with each ID\n",
    "movie_titles = pd.read_csv('movie_titles.txt', header = None, names = ['ID','Year','Name'])\n",
    "print(movie_titles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17771, 2649430)\n"
     ]
    }
   ],
   "source": [
    "# This file is a sparse matrix of movies by user, with each element a rating (1-5) or nonresponse (0)\n",
    "ratings_csr = scipy.sparse.load_npz('netflix_full_csr.npz')\n",
    "print(ratings_csr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid memory overflow errors we have randomly subsampled the data. Some computers can handle the full dataset (e.g. 2017 Macbook Pro can perform SVD on the full dataset). Older computers likely need to subsample the data. You can consider using Princeton computing resources and clusters to perform more computationally expensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n_samples = 5000\n",
    "n_viewers = 10000\n",
    "#random_sample_movies = np.random.choice(17771, size = n_samples)\n",
    "random_sample_viewers = np.random.choice(2649430, size = n_viewers)\n",
    "ratings_small = ratings_csr[:,random_sample_viewers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17771, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common methods for analyzing large datasets is dimension reduction. Here we perform a truncated SVD suited for sparse datasets and analyze which movies are associated with different latent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "svd = TruncatedSVD(n_components = n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = svd.fit_transform(ratings_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "components = svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23049945 0.02934592 0.02127687 0.01800105 0.01420581]\n"
     ]
    }
   ],
   "source": [
    "print(svd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 0\n",
      "1904    Pirates of the Caribbean: The Curse of the Bla...\n",
      "Name: Name, dtype: object: 88.78162789618499\n",
      "11282    Forrest Gump\n",
      "Name: Name, dtype: object: 85.88032850708947\n",
      "4305    The Sixth Sense\n",
      "Name: Name, dtype: object: 81.1467148710099\n",
      "11520    Lord of the Rings: The Two Towers\n",
      "Name: Name, dtype: object: 80.09479985050731\n",
      " \n",
      "Component 1\n",
      "5316    Miss Congeniality\n",
      "Name: Name, dtype: object: 36.60423551376191\n",
      "15204    The Day After Tomorrow\n",
      "Name: Name, dtype: object: 34.53614102489464\n",
      "4995    Gone in 60 Seconds\n",
      "Name: Name, dtype: object: 31.699897842086326\n",
      "15123    Independence Day\n",
      "Name: Name, dtype: object: 31.188924989118423\n",
      " \n",
      "Component 2\n",
      "12231    Lost in Translation\n",
      "Name: Name, dtype: object: 30.27038541655473\n",
      "570    American Beauty\n",
      "Name: Name, dtype: object: 26.345542047122937\n",
      "5861    Memento\n",
      "Name: Name, dtype: object: 25.728237532983837\n",
      "12581    Mystic River\n",
      "Name: Name, dtype: object: 25.589537428172793\n",
      " \n",
      "Component 3\n",
      "4576    Steel Magnolias\n",
      "Name: Name, dtype: object: 28.420705845336435\n",
      "6286    Pretty Woman\n",
      "Name: Name, dtype: object: 27.615657854396634\n",
      "15581    Sweet Home Alabama\n",
      "Name: Name, dtype: object: 25.96055669413163\n",
      "14102    The Notebook\n",
      "Name: Name, dtype: object: 25.494107500096018\n",
      " \n",
      "Component 4\n",
      "16127    Clear and Present Danger\n",
      "Name: Name, dtype: object: 27.67100044057755\n",
      "14312    The Patriot\n",
      "Name: Name, dtype: object: 27.08953065954374\n",
      "5292    Patriot Games\n",
      "Name: Name, dtype: object: 25.278765500186047\n",
      "13650    Air Force One\n",
      "Name: Name, dtype: object: 24.878102511414177\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(0,n_components):\n",
    "    Z_sort = np.argsort(np.abs(Z[:,i]))\n",
    "    print('Component ' + str(i))\n",
    "    for j in range(1,5):\n",
    "        movie_index = Z_sort[-j]\n",
    "        movie_title = movie_titles[movie_titles['ID'] == movie_index]['Name']\n",
    "        movie_weight = Z[movie_index,i]\n",
    "        print(str(movie_title) + ': ' + str(movie_weight))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
